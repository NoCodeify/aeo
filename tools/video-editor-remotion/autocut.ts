/**
 * Auto-cut script - applies cuts.json to speaker video and remaps transcript.
 *
 * Usage:
 *   npx ts-node autocut.ts <video_dir>
 *
 * Example:
 *   npx ts-node autocut.ts ../../youtube/weekly-production/2026-w08-rank-in-chatgpt
 *
 * Prerequisites:
 *   - ffmpeg installed
 *   - cuts.json exists in <video_dir>/video/ (generated by auto-cutter agent)
 *   - transcript.json exists in <video_dir>/video/ (generated by transcribe.ts)
 *
 * Output:
 *   <video_dir>/video/speaker-clean.mp4
 *   <video_dir>/video/transcript-clean.json
 */

import path from "path";
import fs from "fs";
import { execSync } from "child_process";

interface KeepSegment {
  start: number;
  end: number;
}

interface Cut {
  start: number;
  end: number;
  type: string;
  reason: string;
  words?: string[];
}

interface CutsFile {
  originalDuration: number;
  cleanDuration: number;
  savedSeconds: number;
  keepSegments: KeepSegment[];
  cuts: Cut[];
  kept?: any[];
}

interface WordTimestamp {
  word: string;
  start: number;
  end: number;
}

interface SegmentTimestamp {
  start: number;
  end: number;
  text: string;
}

interface Transcript {
  duration: number;
  language: string;
  words: WordTimestamp[];
  segments: SegmentTimestamp[];
  text: string;
}

async function autocut() {
  const args = process.argv.slice(2);

  if (args.length < 1) {
    console.log("Usage: npx ts-node autocut.ts <video_dir>");
    console.log(
      "Example: npx ts-node autocut.ts ../../youtube/weekly-production/2026-w08-rank-in-chatgpt"
    );
    process.exit(1);
  }

  // Check for ffmpeg
  try {
    execSync("ffmpeg -version", { stdio: "ignore" });
  } catch {
    console.error("Error: ffmpeg is not installed or not in PATH.");
    process.exit(1);
  }

  const videoDir = path.resolve(args[0]);
  const videoSubdir = path.join(videoDir, "video");
  const cutsPath = path.join(videoSubdir, "cuts.json");
  const transcriptPath = path.join(videoSubdir, "transcript.json");
  const outputVideoPath = path.join(videoSubdir, "speaker-clean.mp4");
  const outputTranscriptPath = path.join(videoSubdir, "transcript-clean.json");

  // Validate inputs
  if (!fs.existsSync(cutsPath)) {
    console.error("cuts.json not found:", cutsPath);
    console.error("Run the auto-cutter agent first to generate cuts.json");
    process.exit(1);
  }

  if (!fs.existsSync(transcriptPath)) {
    console.error("transcript.json not found:", transcriptPath);
    console.error("Run transcribe.ts first to generate transcript.json");
    process.exit(1);
  }

  // Find speaker video (same logic as render.ts)
  const videoFiles = fs
    .readdirSync(videoSubdir)
    .filter(
      (f) =>
        f.endsWith(".mp4") &&
        !f.includes("test") &&
        !f.includes("output") &&
        !f.includes("clean")
    );

  if (videoFiles.length === 0) {
    console.error("No speaker video found in", videoSubdir);
    process.exit(1);
  }

  const speakerVideoPath = path.join(videoSubdir, videoFiles[0]);

  // Read inputs
  const cuts: CutsFile = JSON.parse(fs.readFileSync(cutsPath, "utf-8"));
  const transcript: Transcript = JSON.parse(
    fs.readFileSync(transcriptPath, "utf-8")
  );

  console.log("=== Auto-Cut ===");
  console.log("Speaker video:", speakerVideoPath);
  console.log("Cuts:", cuts.cuts.length, "cuts to apply");
  console.log("Keep segments:", cuts.keepSegments.length);
  console.log(
    `Duration: ${cuts.originalDuration.toFixed(1)}s → ${cuts.cleanDuration.toFixed(1)}s (saving ${cuts.savedSeconds.toFixed(1)}s / ${((cuts.savedSeconds / cuts.originalDuration) * 100).toFixed(1)}%)`
  );
  console.log();

  if (cuts.keepSegments.length === 0) {
    console.error("No keep segments found in cuts.json");
    process.exit(1);
  }

  // Step 1: Extract keep segments with ffmpeg
  // Only add onset padding after SILENCE cuts (not filler cuts).
  // AssemblyAI timestamps are accurate at word boundaries, so filler cuts
  // already have exact start/end points. Padding after filler cuts pulls
  // the start BACK into the filler word (causing audible filler bleed).
  // FILLER_TAIL_TRIM was removed — it clipped the last word of segments.
  const ONSET_PADDING = 0.10; // 100ms pre-roll for silence cuts only

  // Filler-type cuts have exact word boundaries — no onset padding needed
  const FILLER_CUT_TYPES = new Set([
    "filler", "sentence_start_filler", "trailing_filler", "repeated_word",
  ]);
  // Small trim before filler cuts to catch consonant onsets (e.g. "S" in "So")
  // that start ~50ms before AssemblyAI's reported word boundary.
  // 50ms is imperceptible on real words but prevents filler bleed.
  const FILLER_ONSET_GUARD = 0.05;

  // Build map: which cut type PRECEDES each keep segment
  const cutTypeBeforeSegment = new Map<number, string>();
  for (const cut of cuts.cuts) {
    const segIdx = cuts.keepSegments.findIndex(
      (s) => Math.abs(s.start - cut.end) < 0.05
    );
    if (segIdx >= 0) cutTypeBeforeSegment.set(segIdx, cut.type);
  }

  // Build map: which cut type FOLLOWS each keep segment
  const cutTypeAfterSegment = new Map<number, string>();
  for (const cut of cuts.cuts) {
    const segIdx = cuts.keepSegments.findIndex(
      (s) => Math.abs(s.end - cut.start) < 0.15
    );
    if (segIdx >= 0) cutTypeAfterSegment.set(segIdx, cut.type);
  }

  const tempDir = path.join("/tmp", `autocut-${Date.now()}`);
  fs.mkdirSync(tempDir, { recursive: true });

  console.log("Extracting segments...");
  const segmentFiles: string[] = [];

  for (let i = 0; i < cuts.keepSegments.length; i++) {
    const seg = cuts.keepSegments[i];
    const segFile = path.join(tempDir, `seg_${String(i).padStart(4, "0")}.mp4`);
    segmentFiles.push(segFile);

    // Only pad start after silence cuts (filler cuts have exact word boundaries)
    const cutBefore = cutTypeBeforeSegment.get(i);
    const shouldPad = i > 0 && (!cutBefore || !FILLER_CUT_TYPES.has(cutBefore));
    const paddedStart = shouldPad
      ? Math.max(seg.start - ONSET_PADDING, cuts.keepSegments[i - 1].end)
      : seg.start;
    // Tiny guard trim before filler cuts to catch consonant onsets
    const cutAfter = cutTypeAfterSegment.get(i);
    const paddedEnd = (cutAfter && FILLER_CUT_TYPES.has(cutAfter))
      ? seg.end - FILLER_ONSET_GUARD
      : seg.end;

    try {
      execSync(
        `ffmpeg -ss ${paddedStart} -to ${paddedEnd} -i "${speakerVideoPath}" -c:v libx264 -preset ultrafast -b:v 35M -c:a aac -b:a 192k -avoid_negative_ts make_zero -y "${segFile}"`,
        { stdio: "pipe", timeout: 120000 }
      );
    } catch (err: any) {
      console.error(
        `  Failed to extract segment ${i} (${seg.start}-${seg.end}):`,
        err.stderr?.toString().split("\n").slice(-3).join("\n")
      );
      process.exit(1);
    }
  }
  console.log(`  Extracted ${segmentFiles.length} segments`);

  // Step 2: Create concat file and join segments
  const concatFile = path.join(tempDir, "concat.txt");
  const concatContent = segmentFiles
    .map((f) => `file '${f}'`)
    .join("\n");
  fs.writeFileSync(concatFile, concatContent);

  console.log("Concatenating...");
  try {
    execSync(
      `ffmpeg -f concat -safe 0 -i "${concatFile}" -c copy -movflags +faststart -y "${outputVideoPath}"`,
      { stdio: "pipe", timeout: 300000 }
    );
  } catch (err: any) {
    console.error(
      "Concatenation failed:",
      err.stderr?.toString().split("\n").slice(-5).join("\n")
    );
    process.exit(1);
  }

  const outputSize = (
    fs.statSync(outputVideoPath).size /
    (1024 * 1024)
  ).toFixed(1);
  console.log(`  Output: speaker-clean.mp4 (${outputSize}MB)`);

  // Step 3: Remap transcript timestamps
  console.log("Remapping transcript...");

  // Build time mapping: for each keep segment, track cumulative offset
  let cumulativeCutDuration = 0;
  const timeMap: Array<{
    origStart: number;
    origEnd: number;
    offset: number;
  }> = [];

  for (let i = 0; i < cuts.keepSegments.length; i++) {
    const seg = cuts.keepSegments[i];
    // Use the same padding logic as ffmpeg extraction
    const cutBefore = cutTypeBeforeSegment.get(i);
    const shouldPad = i > 0 && (!cutBefore || !FILLER_CUT_TYPES.has(cutBefore));
    const paddedStart = shouldPad
      ? Math.max(seg.start - ONSET_PADDING, cuts.keepSegments[i - 1].end)
      : seg.start;
    const cutAfterRemap = cutTypeAfterSegment.get(i);
    const paddedEnd = (cutAfterRemap && FILLER_CUT_TYPES.has(cutAfterRemap))
      ? seg.end - FILLER_ONSET_GUARD
      : seg.end;
    if (i > 0) {
      const prevCutAfter = cutTypeAfterSegment.get(i - 1);
      const prevPaddedEnd = (prevCutAfter && FILLER_CUT_TYPES.has(prevCutAfter))
        ? cuts.keepSegments[i - 1].end - FILLER_ONSET_GUARD
        : cuts.keepSegments[i - 1].end;
      cumulativeCutDuration += paddedStart - prevPaddedEnd;
    }
    timeMap.push({
      origStart: paddedStart,
      origEnd: paddedEnd,
      offset: cumulativeCutDuration,
    });
  }

  // Remap a timestamp from original to clean
  function remapTime(t: number): number | null {
    for (const m of timeMap) {
      if (t >= m.origStart && t <= m.origEnd) {
        return Math.round((t - m.offset) * 1000) / 1000;
      }
    }
    return null; // Falls within a cut region
  }

  // Remap words
  const cleanWords: WordTimestamp[] = [];
  for (const word of transcript.words) {
    const newStart = remapTime(word.start);
    const newEnd = remapTime(word.end);
    if (newStart !== null && newEnd !== null) {
      cleanWords.push({
        word: word.word,
        start: newStart,
        end: newEnd,
      });
    }
  }

  // Remap segments
  const cleanSegments: SegmentTimestamp[] = [];
  for (const seg of transcript.segments) {
    const newStart = remapTime(seg.start);
    const newEnd = remapTime(seg.end);
    if (newStart !== null && newEnd !== null) {
      cleanSegments.push({
        start: newStart,
        end: newEnd,
        text: seg.text,
      });
    } else {
      // Segment spans a cut boundary — try to find closest valid timestamps
      // Use the first valid word start and last valid word end within this segment
      const segWords = cleanWords.filter(
        (w) =>
          w.start >= (remapTime(seg.start) ?? -1) &&
          w.end <= (remapTime(seg.end) ?? Infinity)
      );
      if (segWords.length > 0) {
        cleanSegments.push({
          start: segWords[0].start,
          end: segWords[segWords.length - 1].end,
          text: seg.text,
        });
      }
    }
  }

  // Compute clean duration
  const cleanDuration =
    cuts.keepSegments.reduce((sum, seg) => sum + (seg.end - seg.start), 0);

  // Build clean text from remaining words
  const cleanText = cleanWords.map((w) => w.word).join(" ");

  const cleanTranscript: Transcript = {
    duration: cleanDuration,
    language: transcript.language,
    words: cleanWords,
    segments: cleanSegments,
    text: cleanText,
  };

  fs.writeFileSync(
    outputTranscriptPath,
    JSON.stringify(cleanTranscript, null, 2)
  );
  console.log(
    `  Remapped ${cleanWords.length}/${transcript.words.length} words, ${cleanSegments.length}/${transcript.segments.length} segments`
  );

  // Step 4: Cleanup temp files
  fs.rmSync(tempDir, { recursive: true, force: true });

  console.log();
  console.log("=== Done! ===");
  console.log(`Original: ${cuts.originalDuration.toFixed(1)}s`);
  console.log(`Clean:    ${cleanDuration.toFixed(1)}s`);
  console.log(
    `Saved:    ${cuts.savedSeconds.toFixed(1)}s (${((cuts.savedSeconds / cuts.originalDuration) * 100).toFixed(1)}%)`
  );
  console.log(`Video:    ${outputVideoPath}`);
  console.log(`Transcript: ${outputTranscriptPath}`);
}

autocut().catch((err) => {
  console.error("Auto-cut failed:", err);
  process.exit(1);
});
